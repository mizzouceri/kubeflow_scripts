{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c8d7e-385c-4e46-bafc-1cad3f99f76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install PyYAML==5.4.1 --no-build-isolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1585915f-6ab5-4ed8-af1c-c8809fc3f1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install kfp==1.8.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686d8be-e551-4d8e-8031-67c54bd5c28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039f9e6-c29e-45e3-8d35-d0c27c5428cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.notebook\n",
    "import kfp.components as comp\n",
    "from kfp import compiler\n",
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "from kubernetes import client as k8s_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2ca87-793c-4565-ad5d-8c81b747fb00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Preprocess(out_dir: OutputPath(str),dataOrigin:str):\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    \n",
    "    dataURL = \"https://raw.githubusercontent.com/Durbek-Gafur/noshowdata/main/\"+dataOrigin\n",
    "    NoShowData = pd.read_csv(dataURL)\n",
    "    #Convert the variable \"Gender\" to category\n",
    "    NoShowData['Gender'] = NoShowData['Gender'].astype('category')\n",
    "\n",
    "    #Convert the variable \"DOW\" to category\n",
    "    NoShowData['DOW'] = NoShowData['DOW'].astype('category')\n",
    "\n",
    "    #Convert the variable \"SMS_received\" to category\n",
    "    NoShowData['SMS_received'] = NoShowData['SMS_received'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Scholarship\" to category\n",
    "    NoShowData['Scholarship'] = NoShowData['Scholarship'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Smoking_Status\" to category\n",
    "    NoShowData['Smoking_Status'] = NoShowData['Smoking_Status'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Hypertension\" to category\n",
    "    NoShowData['Hypertension'] = NoShowData['Hypertension'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Diabetes\" to category\n",
    "    NoShowData['Diabetes'] = NoShowData['Diabetes'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Alcoholism\" to category\n",
    "    NoShowData['Alcoholism'] = NoShowData['Alcoholism'].astype('category')\n",
    "\n",
    "    #Convert the variable \"Tuberculosis\" to category\n",
    "    NoShowData['Tuberculosis'] = NoShowData['Tuberculosis'].astype('category')\n",
    "    \n",
    "    #Dummy code the columns\n",
    "    try:\n",
    "        NoShowData = pd.get_dummies(NoShowData,\n",
    "        columns=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\", \"Status\"],\n",
    "        prefix=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\", \"Status\"], \n",
    "                                 drop_first = True)\n",
    "    except:\n",
    "        NoShowData = pd.get_dummies(NoShowData,\n",
    "        columns=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\"],\n",
    "        prefix=[\"Gender\",\"DOW\",\"SMS_received\", \"Scholarship\", \"Smoking_Status\", \"Hypertension\", \"Diabetes\", \"Alcoholism\", \"Tuberculosis\"], \n",
    "                                 drop_first = True)\n",
    "    NoShowData.to_csv(out_dir, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SelectFeatureAndSplit(in_dir: InputPath(),\n",
    "                          x_train: OutputPath(str), \n",
    "                          x_test: OutputPath(str),\n",
    "                          y_train: OutputPath(str), \n",
    "                          y_test: OutputPath(str)):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Read the input dataset\n",
    "    NoShowData = pd.read_csv(in_dir)\n",
    "    \n",
    "    # Split the data into predictors and outcome\n",
    "    NoShow_Predictors = pd.DataFrame(NoShowData.iloc[:,:-1])\n",
    "    NoShow_Outcome = pd.DataFrame(NoShowData.iloc[:,-1])\n",
    "    \n",
    "    # Perform train/test split\n",
    "    X_Train_NoShow, X_Test_NoShow, y_Train_NoShow, y_Test_NoShow = train_test_split(\n",
    "        NoShow_Predictors, \n",
    "        NoShow_Outcome, \n",
    "        test_size=0.25, \n",
    "        random_state=8810\n",
    "    )\n",
    "\n",
    "    # Ensure the directories exist for saving outputs\n",
    "    os.makedirs(os.path.dirname(x_train), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(x_test), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(y_train), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(y_test), exist_ok=True)\n",
    "    \n",
    "    # Save the output datasets\n",
    "    X_Train_NoShow.to_csv(x_train, index=False)\n",
    "    X_Test_NoShow.to_csv(x_test, index=False)\n",
    "    y_Train_NoShow.to_csv(y_train, index=False)\n",
    "    y_Test_NoShow.to_csv(y_test, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8abba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TrainClassifier(x_train_dir: InputPath(),y_train_dir: InputPath(), out_dir: OutputPath(str),classifierName:str):\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    if classifierName == \"DecisionTreeClassifier\":\n",
    "        from sklearn.tree import DecisionTreeClassifier as Classifier\n",
    "    elif classifierName == \"RandomForestClassifier\":\n",
    "        from sklearn.ensemble import RandomForestClassifier as Classifier\n",
    "    import pickle\n",
    "    \n",
    "    X_Train_NoShow = pd.read_csv(x_train_dir)\n",
    "    y_Train_NoShow = pd.read_csv(y_train_dir)\n",
    "    model = Classifier()\n",
    "    if classifierName == \"DecisionTreeClassifier\":\n",
    "        model = model.fit(X_Train_NoShow, y_Train_NoShow)\n",
    "    elif classifierName == \"RandomForestClassifier\":\n",
    "        model = model.fit(X_Train_NoShow, y_Train_NoShow.values.ravel())\n",
    "    \n",
    "    with open(out_dir, 'wb') as handle:\n",
    "        pickle.dump(model, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843b7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TestClassifier(pickle_dir: InputPath(),x_test_dir: InputPath(),y_test_dir: InputPath(),classifierName: str) -> float:\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    if classifierName == \"DecisionTreeClassifier\":\n",
    "        from sklearn.tree import DecisionTreeClassifier as Classifier\n",
    "    elif classifierName == \"RandomForestClassifier\":\n",
    "        from sklearn.ensemble import RandomForestClassifier as Classifier\n",
    "    from sklearn import metrics\n",
    "    import pickle\n",
    "    \n",
    "    with open(pickle_dir, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    X_Test_NoShow = pd.read_csv(x_test_dir)\n",
    "    y_Test_NoShow = pd.read_csv(y_test_dir)\n",
    "    \n",
    "    y_pred = model.predict(X_Test_NoShow)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_Test_NoShow, y_pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    return float(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11575579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SmartScheduling(pickle_dir: InputPath(), data_dir: InputPath(),classifierName:str) -> str:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import metrics\n",
    "    import pickle\n",
    "    \n",
    "    with open(pickle_dir, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "        \n",
    "    NoShowData_NewExamples = pd.read_csv(data_dir)\n",
    "    #simulate 20 patient calls and predict their no-show risk\n",
    "    tot_patients = 20\n",
    "    deferred = 0 #initialize deferred to 0\n",
    "    patient_info = NoShowData_NewExamples.sample(tot_patients) #randomly sample 20 patient from the excel file for scheduling\n",
    "    risk_predictions = model.predict(patient_info)\n",
    "\n",
    "    #model parameters:\n",
    "    tot_slots = 10 #total number of available slots for booking\n",
    "    DB = 0 #initilize total double-booked slots to 0\n",
    "    DB_max = 3 #only 3 slots can be double booked (30% of 10 slots)\n",
    "    deferred = 0 #initialize deferred appointments to zero\n",
    "\n",
    "    #initialize the appointment schedule\n",
    "    appointment_schedule = np.empty((tot_slots))\n",
    "    appointment_schedule[:] = np.NaN\n",
    "\n",
    "    appointment_schedule_DB = np.empty((tot_slots))\n",
    "    appointment_schedule_DB[:] = np.NaN\n",
    "\n",
    "    slot_capacity = np.zeros((tot_slots))\n",
    "    slot_capacity.fill(2) #no more than 2 patients per slot\n",
    "\n",
    "    slot_risktype = np.zeros((tot_slots)) #risk type of patient scheduled in a slot\n",
    "    slot_risktype.fill(2) \n",
    "\n",
    "    for p in range(tot_patients): #simulates sequential patient call-in. (i.e., for each patient calling for an appointment)\n",
    "        assignment = 0\n",
    "        if risk_predictions[p] == 1: #patient is low-risk\n",
    "            for slot in range(tot_slots): #start from beginning to search for a slot\n",
    "                if slot_capacity[slot] == 2 and assignment==0:\n",
    "                    appointment_schedule[slot] = p\n",
    "                    assignment = 1\n",
    "                    slot_risktype[slot] = 1 #risk type of patient single booked in this slot is low-risk\n",
    "                    slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "\n",
    "            if assignment == 0 and DB < DB_max: #scan for double-booking \n",
    "                for slot in range(tot_slots): #start from beginning to search for first feasible slot according to overbooking policy\n",
    "                    if slot_capacity[slot] == 1 and slot_risktype[slot] == 0 and assignment==0:\n",
    "                        appointment_schedule_DB[slot] = p\n",
    "                        assignment = 1\n",
    "                        slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "                        DB = DB + 1\n",
    "\n",
    "            if assignment == 0: #if patient is still not scheduled then assign it to \n",
    "                deferred = deferred+1\n",
    "\n",
    "\n",
    "        if risk_predictions[p] == 0: #patient is high-risk\n",
    "            for slot in range(tot_slots-1,-1,-1): #start from end to search for a slot\n",
    "                if slot_capacity[slot] == 2 and assignment==0:\n",
    "                    appointment_schedule[slot] = p\n",
    "                    assignment = 1\n",
    "                    slot_risktype[slot] = 0 #risk type of patient single booked in this slot is high-risk\n",
    "                    slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "\n",
    "            if assignment == 0 and DB < DB_max: #scan for double-booking \n",
    "                for slot in range(tot_slots-1,-1,-1): #start from beginning to search for first feasible slot according to overbooking policy\n",
    "                    if slot_capacity[slot] == 1 and slot_risktype[slot] == 1 and assignment==0:\n",
    "                        appointment_schedule_DB[slot] = p\n",
    "                        assignment = 1\n",
    "                        slot_capacity[slot] = slot_capacity[slot] - 1\n",
    "                        DB = DB + 1\n",
    "\n",
    "            if assignment == 0: #if patient is still not scheduled then assign it to \n",
    "                deferred = deferred+1\n",
    "    with open('output.txt', 'w') as f:\n",
    "        print(f\"Schedule Generated: {appointment_schedule}\\nDoubleBooked Slots: {appointment_schedule_DB}\\nDeferred Patients: {deferred}\",file=f)\n",
    "        \n",
    "    return f\"Schedule Generated: {appointment_schedule}\\nDoubleBooked Slots: {appointment_schedule_DB}\\nDeferred Patients: {deferred}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6a3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetImportantFeatures(pickle_dir: InputPath(), data_dir: InputPath(), classifierName: str ) -> str:\n",
    "    import pandas as pd\n",
    "    import os \n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt \n",
    "    import pickle\n",
    "    import sklearn\n",
    "    \n",
    "    with open(pickle_dir, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    \n",
    "    NoShowData = pd.read_csv(data_dir)\n",
    "    features = list(NoShowData.columns[:-1])\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.title('Feature Importances')\n",
    "    r = \"\"\n",
    "    for i in indices:\n",
    "        r += f\"{features[i]}\\t:\\t{importances[i]}\\n\"\n",
    "            \n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a7ece-c425-408e-8038-583e526fa082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def EvalClassifiers(r1:float, r2:float, pickle1: InputPath(),pickle2: InputPath(), out_dir: OutputPath(str)):\n",
    "    import pickle\n",
    "    import sklearn\n",
    "    if r1>r2:\n",
    "        p = pickle1\n",
    "    else:\n",
    "        p = pickle2\n",
    "    with open(p, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    with open(out_dir, 'wb') as handle:\n",
    "        pickle.dump(model, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b080175",
   "metadata": {},
   "source": [
    "## Turning function to container_operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afed6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocess_op = comp.func_to_container_op(Preprocess,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas'])  \n",
    "\n",
    "selectFeatureAndSplit_op = comp.func_to_container_op(SelectFeatureAndSplit,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','scikit-learn'])  \n",
    "\n",
    "trainClassifier_op = comp.func_to_container_op(TrainClassifier,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','scikit-learn'])  \n",
    "\n",
    "testClassifier_op = comp.func_to_container_op(TestClassifier,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','scikit-learn','pickle-mixin'])  \n",
    "\n",
    "smartScheduling_op = comp.func_to_container_op(SmartScheduling,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','scikit-learn','numpy','pickle-mixin']) \n",
    "\n",
    "getImportantFeatures_op = comp.func_to_container_op(GetImportantFeatures,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pandas','matplotlib','numpy','pickle-mixin','scikit-learn'])  \n",
    "\n",
    "evalClassifiers_op = comp.func_to_container_op(EvalClassifiers,\n",
    "                                              base_image='tensorflow/tensorflow:latest',\n",
    "                                              packages_to_install=['pickle-mixin','scikit-learn'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f2fcad",
   "metadata": {},
   "source": [
    "## Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbdd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=\"Smart Scheduling \",\n",
    "    description=\"Smart Outpatient Appointment Scheduling System\"\n",
    ")\n",
    "def smart_scheduling():\n",
    "    \n",
    "    # Pipeline's task 1 : Download and preprocess data\n",
    "    preprocess_task = preprocess_op(\"No-show_Data.csv\")\n",
    " \n",
    "    # Pipeline's task 2 : Feature Selection and Split Data into Training and Testing\n",
    "    selectFeatureAndSplit_task = selectFeatureAndSplit_op(preprocess_task.output)\n",
    "\n",
    "    # Pipeline's task 3 : Decision Tree Classififer Training\n",
    "    trainClassifier_op_DT_task = trainClassifier_op(selectFeatureAndSplit_task.outputs[\"x_train\"],selectFeatureAndSplit_task.outputs[\"y_train\"],\"DecisionTreeClassifier\")\n",
    " \n",
    "    # Pipeline's task 3 : Random Forest Classifier Training\n",
    "    trainClassifier_op_RF_task = trainClassifier_op(selectFeatureAndSplit_task.outputs[\"x_train\"],selectFeatureAndSplit_task.outputs[\"y_train\"],\"RandomForestClassifier\")\n",
    "\n",
    "    # Pipeline's task 4 : Test Decision Tree Classififer \n",
    "    testClassifier_op_DT_task = testClassifier_op(trainClassifier_op_DT_task.output,selectFeatureAndSplit_task.outputs[\"x_test\"],selectFeatureAndSplit_task.outputs[\"y_test\"],\"DecisionTreeClassifier\")\n",
    " \n",
    "    # Pipeline's task 4 : Test Random Forest Classifier \n",
    "    testClassifier_op_RF_task = testClassifier_op(trainClassifier_op_RF_task.output,selectFeatureAndSplit_task.outputs[\"x_test\"],selectFeatureAndSplit_task.outputs[\"y_test\"],\"RandomForestClassifier\")\n",
    "    \n",
    "    evalClassifiers_task = evalClassifiers_op(testClassifier_op_DT_task.output,testClassifier_op_RF_task.output,trainClassifier_op_DT_task.output,trainClassifier_op_RF_task.output)\n",
    "    # Select Best Classifier \n",
    "    if evalClassifiers_task.output == trainClassifier_op_DT_task.output:\n",
    "        best_classifier = \"DecisionTreeClassifier\"\n",
    "    else:\n",
    "        best_classifier = \"RandomForestClassifier\"\n",
    "        \n",
    "    # Pipeline's task 5 : Identify Variables Important for Predicting No-shows\n",
    "    getImportantFeatures_task = getImportantFeatures_op(evalClassifiers_task.output,preprocess_task.output, best_classifier)\n",
    "    \n",
    "    # Pipeline's task 6 : Predict New Examples\n",
    "    preprocess_new_task = preprocess_op(\"No-show_Data_Testing.csv\")\n",
    "\n",
    "    # Pipeline's task 7 : Smart Scheduling according to prediction\n",
    "    smartScheduling_op(evalClassifiers_task.output, preprocess_new_task.output, best_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad22a758",
   "metadata": {},
   "source": [
    "## Execute pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8cdcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kfp.compiler.Compiler().compile(smart_scheduling, \"smart_scheduling.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23515c3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ls -al ./smart_scheduling.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8732e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -o ./smart_scheduling.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105e4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pygmentize pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649d396",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "EXPERIMENT_NAME = \"Smart Scheduling Experiment 3\"\n",
    "client = kfp.Client()\n",
    "try:\n",
    "    experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "except:\n",
    "    experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "my_run = client.run_pipeline(experiment.id, \"smart-scheduling-pipeline\", \"smart_scheduling.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cef71-beac-44a8-868d-9660d0509005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63121b14-7284-45b0-92df-16ec5d6f4f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "deploy_config": {},
   "docker_image": "gcr.io/arrikto/jupyter-kale-py38@sha256:b7e923046b834491fb5fd90850940cb3b57ba5aedb7d558757d9848db6cb28eb",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": true,
   "storage_class_name": "",
   "volume_access_mode": "rwm",
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "dgvkh-jupyter-workspace-zln2x",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
